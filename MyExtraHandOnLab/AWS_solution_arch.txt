<Domain 1>: Design Resilient Architectures
- Multi-tier solution - Base on the Access Pattern to design the architecture; eg. traffic
Do you have steady connections, or do you have peaks to consider?
Do your requests vary in size, or are they fairly consistent?
Do you need to be ready for large volumes of unexpected traffic?
When studying this area, make sure you are considering how scaling can occur at each level of your multi-tiered architecture, as well as the possible use of both horizontal and vertical scaling methods.

- High Availability and Fault Tolerance
Designing for high availability means designing for minimal downtime.
Designing for fault tolerance means designing for zero downtime.
Determine the amount of resources needed.
Determine which AWS services can be used to improve reliability.
Select highly available configurations to mitigate single point of failure, and select appropriate disaster recovery strategies.
Evaluating the needs of environments and architectures, assessing how to implement high availability and fault tolerance, and determining how and when to implement disaster recovery strategies make up the major themes for this section.

- Decoupling Mechanisms
Decoupling refers to components remaining autonomous and unaware of each other as they complete their work as part of a larger system.
Decoupling techniques: synchronous and asynchronous integration.
Synchronous decoupling involves components that must always be available for proper functionality. (eg, Load Balancer)
Asynchronous decopling involves communication between components through durable components. (eg. SQS, service can temporary offline)
Knowing how to utilize decoupling services will be incredibly important.
Decoupling services: eg. Load Balancer, Event Bridge
Serverless tools in AWS help improve decoupling mechanisms. eg. SQS, API Gateway, DynamoDB

- Resilient Storage
Define your strategy to ensure the durability of data.
Identify how data service consistency will affect operations.
Know how to implement across a variety of architectures, including hybird and no-cloud-native applications.
Storage type: Amazon Elastic Block Store, Amazon EC2 instance store, S3
Consideration: data durability, ephermeral, data interchangeably (eg. S3 and S3 Glacier), data consistency, access pattern (eg. access by global user, large file or small file), 
S3 not provide File System; EC2 instance store is not ephemeral and only attach to single instance; EBS volume cannot be mounted across different AZ.
EFS provide File system, and can be run across AZ.


<Domain 2>: Design High-Performing Architectures
- Elastic and Scalable Compute Solutions for a Workload
Identify elastic and scalable compute solutions for a workload.
Some services in AWS are elastic by nature automatically, without you needing to do anything, like AWS Lambda, for example.
Amazon EC2 is a service that is not inherently scalable.
Choose the appropriate architecture and servicdes that scale to meet performance requirements.
EC2 usually use with Load Balancer and Auto Scaling to make it scalable.
Possible solution are: EC2, ECS, Lambda (can only run for 15 mins.)
SQS can help to decouple the multi tier loading

-High-performing and Scalable Storage Solutions for a Workload
Amazon EBS Volume Attached to EC2; Scale by changing the volume size; Scale by attaching more volumes
Amazon EFS Mount to EC2; Scales Automatically 
Determine which storage solution is the best fist based on future storage needes.
Know general upper bounds for the capacity of storage solutions.
Determine which solution would be the most appropriate for a situation based on performance.
Amazon EBS volumes are extremely low latency (high performance, but lower flexibility)
Familiarize yourself with S3: Basic API calls, Multipart uploads, Amazon S3 Accelerator, Caching with Amazon CloudFront
Besing able to determione which storage services to use that can scale to accommodate current and future storage needs, and choosing AWS services and configurations what meet performance needs under different circumstances.
AWS CLI can execute multipart upload to S3 automatically (multipart uploades for objects is suggested to be over 100MB; ie. 90M shouldn't run multipart upload; and AWS CLI can auto detect and execute the multipart upload; AWS management console (the portal) can't perform auto upload automatically)

- High-performing Networking Solutions for a Workload
Select high-performing networking solutions for a workload given a defined set of requirements or circumstances.
On permises data center and AWS clound (hybird mode is very common); AWS Managed VPN and AWS Driect Connect are the services for on permises and cloud connection
AWS networking connectivity services: AWS Managed VPN, AWS Direct Connect, AWS Transit Gateway, AWS VPN CloudHub
Connectivity between VPCs: VPC peering, AWS Transit Gateway, AWS PrivateLink, AWS Managed VPN
Amazon Route53 routing policies (eg. geoproximity)
AWS Global Accelerator can improve application network performance.
Consider caching assets closer to your end users by using Amazon CloudFront.
Data transfer serices: AWS DataSync, AWS Snow Family, AWS Transfer Family, AWS Databae Migration Service (AWS DMS)
AWS Private Link is best used when you have a client-server setup where you want to allow one or more consumer VPCs unidirectional access to a specific service in the service-provider VPC.
VPC peering connection have limitation on the number of peering connections. One VPC accept up to 125 peering connections.

- High-performing Database Solutions for a Workload
You need to be able to identify which AWS Service to use for non-relational databases, relational databases, graph databases, and more.
If you have a use casethat needs single-digit-millisecond response times, then Amazon DynamoDB (Amazon RDS can't achieve that fast) would likely be a better choice for that solution.
Know the differences (limitation and performance) between Amazon Relational Database Service (Amazon RDS) and Amazon Aurora.
Amazon RDS storage types: General Purpose SSD, Provisioned IOPs SSD, Magnetic
Beyond choosing services or features that best fit a use case and performance needs, you should also be able to choose appropriate scaling strategies to meet your scaling needs.
Amazon DynamoDB automatically scales storage and you retain control over scaling throughput.
To scale Amazon RDS, update the DB instance, use storage auto scaling, or use read replicas.
Know when to use Amazon ElastiCache for caching, and the impacts on performance.
Amazon Neptune, the graph database.
DynamoDB is a key-value database that can scale automatically and handle spiky access patterns.
Example of stroring IoT streaming data: Amazon DynamoDB -> Amazon DynamoDB Streams -> Amazon Kinesis Data Streams -> Amazon Kinesis Data Firehose -> Amazon S3 Data Lake

- Design High-Performing Architectures [Conclusion]
Solution Layers: Compute, Storage, Database, Networking
Understand the scaling mechanisms for the different compute services.
Understand Amazon EC2 Auto Scaling step by step.
You should understand cluster scaling for container services, as well as concurrency rates for AWS Lambda.
Consider where the service you are using resides in the AWS global infrastructure. (eg. across AZ or Regions)
Knowing how to take and manage EBS volume snapshots is an important part of setting up block-storage solutions.
Know when to offload data requests to caches to increase performance.
Using read replicas for Amazon RDS, DynamoDB Accelerator for DynamoDB, or Amazon ElastiCache for Redis, or for Memcached.
Understand Amazon Route 53, the different record types, the different routing methods, and how Regional failover works.
Know how to: Create a VPC, Create Subnets, Use network ACLs, Use security groups, Use route table, Use gateways.
Networking services and features to study: AWS Managed VPN, AWS Direct Connect, AWS Transit Gateway, VPC Peering, AWS PrivateLink, VPC endpoints,



<Domain 3>: Design Secure Applications and Architectures
- Secure Resource Access
Consider security at every level.
Domain segments: Design secure access to AWS services; Design secure application tiers; Select appropriate data security options
AWS Identity and Access Management (IAM)
Never hardcode credentials into your application
Accerss Key ID and secret access key is for programmatic request.
Roles are used for services.

- Secure Application Tiers
Pay significant attention to the use and functionality of security groups and network access control lists (network ACLs).
Network segmentation. Understand the strategies behind when to use public and private subnets.
Understand routing mechanisms within a virtual private cloud (VPC).
Select and deploy other components, such as AWS service endpoints, VPN connections.
Select appropriate AWS services to protect applications from external threats.

- Data Security Options
What methods are available within AWS to secure your data, both at rest and in transit?
VPN over the internet; a private connection through AWS Direct Connect; connections between VPCs; transfer between services, such as Amazon Simple Storage Service, and your VPC;
How do the various data management and storage services handle data protection?
As an example, how would that differ when looking at S3 versus Elastic Block Store, and does the use of those protections change the performance of the services?
What are your encryption options in AWS?
How are encryption keys handled?
Look into data security based on access patterns.
AWS Key Management Service (KMS) can generate AWS KMS keys and data keys. 

- Design Secure Applications and Architectures: Conslusion
IAM, Security Groups, Network ACLs, Route tables, Protecting Data at Rest, Protecting Data in Transit, Encrypting Data at Rest and in Transit


<Domain 4> Design Cost-Optimized Architectures
- Cost-effective Storage Solutions
S3 is object storage and not file storage (file system); Make sure which service fit for your application; then consider the cost-optimized solution
Ways to optimize Amazon EBS for cost: Right-size EBS volumes; Choose the appropriate volume type; Use services like AWS Trusted Advisor; Delete old EBS snapshots
S3 offers different storage tiers that have varying pricing
S3 Standard storage class, which incurs the highest cost for storage, (storage cost vs retrieval cost)
you can automate storage tiering for services like S3 (S3 intelligent-Tiering can automiatically optimize for cost by changing storage tiers based on usage patterns.)
AWS Backup is a backup service that automates backup processes for application data across AWS services in the AWS Cloud, including Amazon EBS.
Amazon DLM enables you to manage the lifecycle of your AWS resources through lifecycle policies.

- Cost-effective Compute and Database Services
Amazon EC2 pricing models: On-Demand Instances (use to serve the unknow processing), Reserved Instances (if you know there must be some fixed usage), Dedicated Instances, Spot Instances (for very peak of usage), Savings Plans
Reserved Instances can also be used for Amazon RDS database instances, which can further cost optimization.
EC2 should also consider the instance size and family for cost optimization (base on monitoring, you can scale down if most of the time are very low utilization)
Right-sizing EC2 instances and RDS DB instances are a good way to optimize for cost.
For DB, you can "increaes the instance size for DB" OR "add a read replica and cache to reduce the loading and hence keep the instance size" (this meet performance and optimize the cost)
Auto scaling also help to optize the cost for both compute and database
for cost optimization for compute and databases is to use managed services when possible. (AWS managed service)
This means you should consider using managed services like AWS Fargate for containers, AWS Lambda for serverless compute, or Amazon DynamoDB for a database. (those AWS service may add some cost, but it save your admin time and hence save the money)

- Cost-optimized Network Architectures
Remember that data transfer and API calls can potentially incur costs.
Using S3 incurs charges for the amount of data stored in the S3 bucket, but it also incurs costs for API calls made to S3, as well as data transfer out of the bucket.
Use CloudFront to optimize the cost of S3; Route 53 <-> CloudFront <-> S3; CloudFront cache the S3 data and reduce the traffic from S3
Determine strategies for reducing dta transfer costs within AWS.
Understand the cost differences between using AWS Managed VPN and AWS Direct Connect.
Aware the cost of other networking services, like NAT gateways or transit gateways.
Session Manager enables you to set up secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys. This makes it a great option for accessing private instances, because you do not need to open up any ports, and it's also very cost-effective because it comes at no extra charge.

- Design Cost-optimized Architectures: Conclusion
For Amazon EC2, choose the appropriate pricing model for the use case.
For AWS Lambda, consider runtime and resource comsumption. This means you can optimize by writing functions that consume fewer resources, and are more efficient for runtime.
For containers, it can be a similar thing. You can save by having smaller, more lightweight containers, and choosing the correct compute platform for your cluster, whether that is Amazon EC2 or AWS Fargate.
For Amazon S3, use the appropriate storage tier for the use case.
For Amazon EBS, choose the appropriate volume type and automate the management of the snapshot lifecycle.
For databases, choose the most-aligned database for the use case. Consider caching mechanisms for cost savings, and also consider database design.
You should look into how to take advantage of caching, instead of always scaling up or scaling out.
For networking, choose the correct connectivity service for the use case.


